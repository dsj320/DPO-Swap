import argparse, os, sys, datetime, glob
import numpy as np
import time
import torch
import torchvision
import pytorch_lightning as pl
import shutil

from packaging import version
from omegaconf import OmegaConf
from torch.utils.data import DataLoader, Dataset
from functools import partial
from PIL import Image

from pytorch_lightning import seed_everything
from pytorch_lightning.trainer import Trainer
from pytorch_lightning.callbacks import ModelCheckpoint, Callback, LearningRateMonitor
from pytorch_lightning.utilities.distributed import rank_zero_only
from pytorch_lightning.utilities import rank_zero_info

from ldm.data.base import Txt2ImgIterableBaseDataset
from ldm.util import instantiate_from_config
import wandb
wandb.login(key="f0a412d675fd5439a95ac8369fe5fe7b6acf6fc7")


def get_parser(**parser_kwargs):
    def str2bool(v):
        if isinstance(v, bool):
            return v
        if v.lower() in ("yes", "true", "t", "y", "1"):
            return True
        elif v.lower() in ("no", "false", "f", "n", "0"):
            return False
        else:
            raise argparse.ArgumentTypeError("Boolean value expected.")

    parser = argparse.ArgumentParser(**parser_kwargs)
    parser.add_argument(
        "-n",
        "--name",
        type=str,
        const=True,
        default="",
        nargs="?",
        help="postfix for logdir",
    )
    parser.add_argument(
        "-r",
        "--resume",
        type=str,
        const=True,
        default="",
        nargs="?",
        help="resume from logdir or checkpoint in logdir",
    )
    parser.add_argument(
        "-b",
        "--base",
        nargs="*",
        metavar="base_config.yaml",
        help="paths to base configs. Loaded from left-to-right. "
             "Parameters can be overwritten or added with command-line options of the form `--key value`.",
        default=["configs/train_dpo.yaml"],  # ä¿®æ”¹é»˜è®¤å€¼ä¸ºtrain_dpo.yaml
    )
    parser.add_argument(
        "-t",
        "--train",
        type=str2bool,
        const=True,
        default=True,
        nargs="?",
        help="Is train",
    )
    parser.add_argument(
        "--no-test",
        type=str2bool,
        const=True,
        default=False,
        nargs="?",
        help="disable test",
    )
    parser.add_argument(
        "-d",
        "--debug",
        type=str2bool,
        nargs="?",
        const=True,
        default=False,
        help="enable post-mortem debugging",
    )
    parser.add_argument(
        "-s",
        "--seed",
        type=int,
        default=23,
        help="seed for seed_everything",
    )
    parser.add_argument(
        "-f",
        "--postfix",
        type=str,
        default="",
        help="post-postfix for default name",
    )
    parser.add_argument(
        "-l",
        "--logdir",
        type=str,
        default="models/REFace/Debug",
        help="directory for logging dat shit",
    )
    parser.add_argument(
        "--pretrained_model",
        type=str,
        default="checkpoints/model.ckpt",
        help="path to pretrained model",
    )
    parser.add_argument(
        "--scale_lr",
        type=str2bool,
        nargs="?",
        const=True,
        default=False,
        help="scale base-lr by ngpu * batch_size * n_accumulate",
    )
    return parser


def nondefault_trainer_args(opt):
    parser = argparse.ArgumentParser()
    parser = Trainer.add_argparse_args(parser)
    args = parser.parse_args([])
    return sorted(k for k in vars(args) if getattr(opt, k) != getattr(args, k))


class WrappedDataset(Dataset):
    """Wraps an arbitrary object with __len__ and __getitem__ into a pytorch dataset"""

    def __init__(self, dataset):
        self.data = dataset

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]


def worker_init_fn(_):
    worker_info = torch.utils.data.get_worker_info()

    dataset = worker_info.dataset
    worker_id = worker_info.id

    if isinstance(dataset, Txt2ImgIterableBaseDataset):
        split_size = dataset.num_records // worker_info.num_workers
        # reset num_records to the true number to retain reliable length information
        dataset.sample_ids = dataset.valid_ids[worker_id * split_size:(worker_id + 1) * split_size]
        current_id = np.random.choice(len(np.random.get_state()[1]), 1)
        return np.random.seed(np.random.get_state()[1][current_id] + worker_id)
    else:
        return np.random.seed(np.random.get_state()[1][0] + worker_id)



class DataModuleFromConfig(pl.LightningDataModule):    
    def __init__(self, batch_size, train=None, validation=None, test=None, predict=None,
                 wrap=False, num_workers=None, shuffle_test_loader=False, use_worker_init_fn=False,
                 shuffle_val_dataloader=False):
        super().__init__()
        self.batch_size = batch_size
        self.dataset_configs = dict()
        self.num_workers = num_workers if num_workers is not None else batch_size * 2
        self.use_worker_init_fn = use_worker_init_fn
        if train is not None:
            self.dataset_configs["train"] = train
            self.train_dataloader = self._train_dataloader
        if validation is not None:
            self.dataset_configs["validation"] = validation
            self.val_dataloader = partial(self._val_dataloader, shuffle=shuffle_val_dataloader)
        if test is not None:
            self.dataset_configs["test"] = test
            self.test_dataloader = partial(self._test_dataloader, shuffle=shuffle_test_loader)
        if predict is not None:
            self.dataset_configs["predict"] = predict
            self.predict_dataloader = self._predict_dataloader
        self.wrap = wrap

    def prepare_data(self):
        for data_cfg in self.dataset_configs.values():
            instantiate_from_config(data_cfg)

    def setup(self, stage=None):
        self.datasets = dict(
            (k, instantiate_from_config(self.dataset_configs[k]))
            for k in self.dataset_configs)
        if self.wrap:
            for k in self.datasets:
                self.datasets[k] = WrappedDataset(self.datasets[k])

    def _train_dataloader(self):
        is_iterable_dataset = isinstance(self.datasets['train'], Txt2ImgIterableBaseDataset)
        if is_iterable_dataset or self.use_worker_init_fn:
            init_fn = worker_init_fn
        else:
            init_fn = None
        return DataLoader(self.datasets["train"], batch_size=self.batch_size,
                          num_workers=self.num_workers, shuffle=False if is_iterable_dataset else True,
                          worker_init_fn=init_fn,
                          persistent_workers=True if self.num_workers > 0 else False)

    def _val_dataloader(self, shuffle=False):
        if isinstance(self.datasets['validation'], Txt2ImgIterableBaseDataset) or self.use_worker_init_fn:
            init_fn = worker_init_fn
        else:
            init_fn = None
        return DataLoader(self.datasets["validation"],
                          batch_size=self.batch_size,
                          num_workers=self.num_workers,
                          worker_init_fn=init_fn,
                          shuffle=shuffle,
                          persistent_workers=True if self.num_workers > 0 else False)

    def _test_dataloader(self, shuffle=False):
        is_iterable_dataset = isinstance(self.datasets['train'], Txt2ImgIterableBaseDataset)
        if is_iterable_dataset or self.use_worker_init_fn:
            init_fn = worker_init_fn
        else:
            init_fn = None

        # do not shuffle dataloader for iterable dataset
        shuffle = shuffle and (not is_iterable_dataset)

        return DataLoader(self.datasets["test"], batch_size=self.batch_size,
                          num_workers=self.num_workers, worker_init_fn=init_fn, shuffle=shuffle,
                          persistent_workers=True if self.num_workers > 0 else False)

    def _predict_dataloader(self, shuffle=False):
        if isinstance(self.datasets['predict'], Txt2ImgIterableBaseDataset) or self.use_worker_init_fn:
            init_fn = worker_init_fn
        else:
            init_fn = None
        return DataLoader(self.datasets["predict"], batch_size=self.batch_size,
                          num_workers=self.num_workers, worker_init_fn=init_fn,
                          persistent_workers=True if self.num_workers > 0 else False)


class SetupCallback(Callback):
    def __init__(self, resume, now, logdir, ckptdir, cfgdir, config, lightning_config):
        super().__init__()
        self.resume = resume
        self.now = now
        self.logdir = logdir
        self.ckptdir = ckptdir
        self.cfgdir = cfgdir
        self.config = config
        self.lightning_config = lightning_config

    def on_keyboard_interrupt(self, trainer, pl_module):
        if trainer.global_rank == 0:
            print("Summoning checkpoint.")
            ckpt_path = os.path.join(self.ckptdir, "last.ckpt")
            trainer.save_checkpoint(ckpt_path)
    
    def save_code_snapshot(self):
        """ä¿å­˜ä»£ç å¿«ç…§åˆ°æ—¥å¿—ç›®å½•"""
        # åˆ›å»ºä»£ç å¿«ç…§ç›®å½•
        snapshot_dir = os.path.join(self.logdir, "code_snapshot")
        os.makedirs(snapshot_dir, exist_ok=True)
        
        # é¡¹ç›®æ ¹ç›®å½•ï¼ˆç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•ï¼‰
        project_root = "/data5/shuangjun.du/work/REFace"
        
        # éœ€è¦ä¿å­˜çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
        files_to_snapshot = [
            "train_sft.sh",
            "main_dpo.py",
            "ldm/data/dpo_dataset.py",
            "ldm/models/diffusion/ddpm_dpo.py",
        ]
        
        print("\n" + "="*80)
        print("ğŸ“¸ Creating code snapshot...")
        print("="*80)
        
        for rel_path in files_to_snapshot:
            src_file = os.path.join(project_root, rel_path)
            
            # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(src_file):
                print(f"âš ï¸  Warning: {rel_path} not found, skipping...")
                continue
            
            # åœ¨å¿«ç…§ç›®å½•ä¸­åˆ›å»ºç›¸åŒçš„å­ç›®å½•ç»“æ„
            dst_file = os.path.join(snapshot_dir, rel_path)
            dst_dir = os.path.dirname(dst_file)
            os.makedirs(dst_dir, exist_ok=True)
            
            # å¤åˆ¶æ–‡ä»¶
            try:
                shutil.copy2(src_file, dst_file)
                print(f"âœ“ Saved: {rel_path}")
            except Exception as e:
                print(f"âœ— Failed to save {rel_path}: {e}")
        
        # ä¿å­˜å½“å‰æ—¶é—´æˆ³
        timestamp_file = os.path.join(snapshot_dir, "snapshot_info.txt")
        with open(timestamp_file, 'w') as f:
            f.write(f"Snapshot created at: {self.now}\n")
            f.write(f"Training started: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Working directory: {os.getcwd()}\n")
            f.write(f"\nSnapshot files:\n")
            for rel_path in files_to_snapshot:
                f.write(f"  - {rel_path}\n")
        
        print(f"âœ“ Snapshot info saved to: {os.path.relpath(timestamp_file, os.getcwd())}")
        print("="*80 + "\n")

    def on_pretrain_routine_start(self, trainer, pl_module):
        if trainer.global_rank == 0:
            # Create logdirs and save configs
            os.makedirs(self.logdir, exist_ok=True)
            os.makedirs(self.ckptdir, exist_ok=True)
            os.makedirs(self.cfgdir, exist_ok=True)

            if "callbacks" in self.lightning_config:
                if 'metrics_over_trainsteps_checkpoint' in self.lightning_config['callbacks']:
                    os.makedirs(os.path.join(self.ckptdir, 'trainstep_checkpoints'), exist_ok=True)
            
            # ğŸ“¸ ä¿å­˜ä»£ç å¿«ç…§
            self.save_code_snapshot()
            
            print("Project config")
            print(OmegaConf.to_yaml(self.config))
            OmegaConf.save(self.config,
                           os.path.join(self.cfgdir, "{}-project.yaml".format(self.now)))

            print("Lightning config")
            print(OmegaConf.to_yaml(self.lightning_config))
            OmegaConf.save(OmegaConf.create({"lightning": self.lightning_config}),
                           os.path.join(self.cfgdir, "{}-lightning.yaml".format(self.now)))

        else:
            # ModelCheckpoint callback created log directory --- remove it
            if not self.resume and os.path.exists(self.logdir):
                dst, name = os.path.split(self.logdir)
                dst = os.path.join(dst, "child_runs", name)
                os.makedirs(os.path.split(dst)[0], exist_ok=True)
                try:
                    os.rename(self.logdir, dst)
                except FileNotFoundError:
                    pass


class ImageLogger(Callback):
    def __init__(self, batch_frequency, max_images, clamp=True, increase_log_steps=True,
                 rescale=True, disabled=False, log_on_batch_idx=False, log_first_step=False,
                 log_images_kwargs=None):
        super().__init__()
        self.rescale = rescale
        self.batch_freq = batch_frequency
        self.max_images = max_images
        self.logger_log_images = {
            pl.loggers.TestTubeLogger: self._testtube,
            pl.loggers.WandbLogger: self._wandb,
        }
        self.log_steps = [2 ** n for n in range(int(np.log2(self.batch_freq)) + 1)]
        if not increase_log_steps:
            self.log_steps = [self.batch_freq]
        self.clamp = clamp
        self.disabled = disabled
        self.log_on_batch_idx = log_on_batch_idx
        self.log_images_kwargs = log_images_kwargs if log_images_kwargs else {}
        self.log_first_step = log_first_step

    @rank_zero_only
    def _testtube(self, pl_module, images, batch_idx, split):
        for k in images:
            grid = torchvision.utils.make_grid(images[k])
            grid = (grid + 1.0) / 2.0  # -1,1 -> 0,1; c,h,w

            tag = f"{split}/{k}"
            pl_module.logger.experiment.add_image(
                tag, grid,
                global_step=pl_module.global_step)

    @rank_zero_only
    def _wandb(self, pl_module, images, batch_idx, split):
        """è®°å½•å›¾åƒåˆ° wandb - æ‹¼æ¥æˆ 2 è¡Œå¸ƒå±€ï¼ˆå¤„ç†ä¸åŒå°ºå¯¸ï¼‰- éé˜»å¡ç‰ˆæœ¬"""
        try:
            print(f"[_wandb] Called with {len(images)} images: {list(images.keys())}")
            
            if wandb.run is None:
                print("WARNING: wandb.run is None, skipping image logging")
                return
            
            from PIL import Image as PILImage
            import torch.nn.functional as F
            
            # æ ¹æ®æ˜¯å¦æœ‰å‚è€ƒæ¨¡å‹è¾“å‡ºï¼Œå®šä¹‰è¦æ˜¾ç¤ºçš„å›¾åƒé¡ºåºï¼ˆæ¯è¡Œä¸€ç§ç±»å‹ï¼‰
            has_reference = 'output_reference' in images
            
            if has_reference:
                # DPO æ¨¡å¼ï¼šæœ‰å‚è€ƒæ¨¡å‹ï¼ˆ5è¡Œï¼‰
                # ç¬¬ 1 è¡Œï¼šsrc
                # ç¬¬ 2 è¡Œï¼štgt
                # ç¬¬ 3 è¡Œï¼šwinner
                # ç¬¬ 4 è¡Œï¼šloser
                # ç¬¬ 5 è¡Œï¼šoutput_reference
                # ç¬¬ 6 è¡Œï¼šoutput_current
                row_keys_list = ['src', 'tgt', 'winner', 'loser', 'output_reference', 'output_current']
            else:
                # SFT æ¨¡å¼ï¼šæ— å‚è€ƒæ¨¡å‹ï¼ˆ4è¡Œï¼‰
                # ç¬¬ 1 è¡Œï¼šsrc
                # ç¬¬ 2 è¡Œï¼štgt
                # ç¬¬ 3 è¡Œï¼šwinner
                # ç¬¬ 4 è¡Œï¼šoutput_current
                row_keys_list = ['src', 'tgt', 'winner', 'output_current']
            
            def resize_tensor_to_512(tensor):
                """å°† tensor resize åˆ° 512x512"""
                # tensor: [B, C, H, W]
                if tensor.shape[2] == 512 and tensor.shape[3] == 512:
                    return tensor
                print(f"    Resizing from {tensor.shape[2]}x{tensor.shape[3]} to 512x512")
                return F.interpolate(tensor, size=(512, 512), mode='bilinear', align_corners=False)
            
            def create_single_row_grid(key):
                """ä¸ºå•ä¸ªç±»å‹åˆ›å»ºä¸€è¡Œ gridï¼ˆæ¨ªå‘æ˜¾ç¤ºæ‰€æœ‰æ ·æœ¬ï¼‰"""
                if key not in images:
                    return None
                
                img_tensor = images[key].detach().cpu()
                # ç»Ÿä¸€ resize åˆ° 512
                img_tensor = resize_tensor_to_512(img_tensor)
                
                print(f"  Creating row for {key}: shape={img_tensor.shape}")
                
                # åˆ›å»º grid: æ‰€æœ‰æ ·æœ¬æ¨ªå‘æ’åˆ—
                grid = torchvision.utils.make_grid(
                    img_tensor,
                    nrow=img_tensor.shape[0],  # æ‰€æœ‰æ ·æœ¬æ”¾åœ¨ä¸€è¡Œ
                    normalize=True,
                    value_range=(-1, 1),
                    padding=2
                )
                
                # è½¬æ¢ä¸º PIL
                grid_np = grid.permute(1, 2, 0).numpy()
                grid_np = np.clip(grid_np, 0, 1)
                grid_np = (grid_np * 255).astype(np.uint8)
                return PILImage.fromarray(grid_np)
            
            # ç”Ÿæˆæ¯ä¸€è¡Œ
            pil_rows = []
            for key in row_keys_list:
                print(f"[_wandb] Creating row for: {key}")
                pil_row = create_single_row_grid(key)
                if pil_row is not None:
                    pil_rows.append(pil_row)
            
            if not pil_rows:
                print("[_wandb] No valid images to create grid")
                return
            
            # å‚ç›´æ‹¼æ¥æ‰€æœ‰è¡Œ
            max_width = max(row.width for row in pil_rows)
            total_height = sum(row.height for row in pil_rows)
            
            final_img = PILImage.new('RGB', (max_width, total_height), (255, 255, 255))
            
            current_y = 0
            for i, pil_row in enumerate(pil_rows):
                final_img.paste(pil_row, (0, current_y))
                current_y += pil_row.height
                print(f"[_wandb] Pasted row {i+1} at y={current_y - pil_row.height}")
            
            print(f"[_wandb] Final grid: {final_img.size} with {len(pil_rows)} rows")
            
            # â­ å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ commit=False é¿å…é˜»å¡
            # wandbä¼šåœ¨åå°å¼‚æ­¥ä¸Šä¼ ï¼Œä¸ä¼šé˜»å¡è®­ç»ƒ
            # ç”Ÿæˆæè¿°
            mode = "DPO" if has_reference else "SFT"
            rows_desc = " | ".join([f"Row{i+1}: {key}" for i, key in enumerate(row_keys_list) if key in images])
            caption = f"Step {pl_module.global_step} | {mode} Mode | {rows_desc}"
            
            # åœ¨é”®åä¸­åŒ…å«æ­¥æ•°ï¼Œä½¿æ–‡ä»¶åæ›´æ¸…æ™°
            wandb_log = {
                f"{split}/all_samples_step_{pl_module.global_step:06d}": wandb.Image(
                    final_img,
                    caption=caption
                )
            }
            
            # â­ commit=False: ä¸ç«‹å³åŒæ­¥ï¼Œç”±wandbåå°å¤„ç†
            wandb.log(wandb_log, step=pl_module.global_step, commit=False)
            print(f"âœ“ Successfully queued image to wandb at step {pl_module.global_step} (non-blocking)")
                
        except Exception as e:
            print(f"âœ— ERROR logging images to wandb: {e}")
            import traceback
            traceback.print_exc()

    @rank_zero_only
    def log_local(self, save_dir, split, images,
                  global_step, current_epoch, batch_idx):
        root = os.path.join(save_dir, "images", split)
        for k in images:
            grid = torchvision.utils.make_grid(images[k], nrow=4)
            if self.rescale:
                grid = (grid + 1.0) / 2.0  # -1,1 -> 0,1; c,h,w
            grid = grid.transpose(0, 1).transpose(1, 2).squeeze(-1)
            grid = grid.numpy()
            grid = (grid * 255).astype(np.uint8)
            filename = "{}_gs-{:06}_e-{:06}_b-{:06}.png".format(
                k,
                global_step,
                current_epoch,
                batch_idx)
            path = os.path.join(root, filename)
            os.makedirs(os.path.split(path)[0], exist_ok=True)
            Image.fromarray(grid).save(path)

    def log_img(self, pl_module, batch, batch_idx, split="train"):
        check_idx = batch_idx if self.log_on_batch_idx else pl_module.global_step
        
        if (self.check_frequency(check_idx) and  # batch_idx % self.batch_freq == 0
                hasattr(pl_module, "log_images") and
                callable(pl_module.log_images) and
                self.max_images > 0):
            logger = type(pl_module.logger)

            is_train = pl_module.training
            if is_train:
                pl_module.eval()

            with torch.no_grad():
                images = pl_module.log_images(batch, split=split, **self.log_images_kwargs)
            
            for k in images:
                N = min(images[k].shape[0], self.max_images)
                images[k] = images[k][:N]
                if isinstance(images[k], torch.Tensor):
                    images[k] = images[k].detach().cpu()
                    if self.clamp:
                        images[k] = torch.clamp(images[k], -1., 1.)
            
            self.log_local(pl_module.logger.save_dir, split, images,
                           pl_module.global_step, pl_module.current_epoch, batch_idx)

            # è®°å½•åˆ° PyTorch Lightning loggerï¼ˆtesttubeï¼‰
            logger_log_images = self.logger_log_images.get(logger, lambda *args, **kwargs: None)
            logger_log_images(pl_module, images, pl_module.global_step, split)
            
            # åŒæ—¶è®°å½•åˆ° wandbï¼ˆæ— è®ºç”¨ä»€ä¹ˆ loggerï¼‰
            self._wandb(pl_module, images, batch_idx, split)

            if is_train:
                pl_module.train()

    def check_frequency(self, check_idx):
        if ((check_idx % self.batch_freq) == 0 or (check_idx in self.log_steps)) and (
                check_idx > 0 or self.log_first_step):
            try:
                self.log_steps.pop(0)
            except IndexError as e:
                print(e)
                pass
            return True
        return False

    @rank_zero_only  # â† ä¿®å¤ï¼šåªåœ¨ä¸»è¿›ç¨‹æ‰§è¡Œï¼Œé¿å…å¤šGPUé‡å¤è°ƒç”¨å¯¼è‡´æ­»é”
    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):
        print(f"[ImageLogger.on_train_batch_end] Called at global_step={pl_module.global_step}, batch_idx={batch_idx}, disabled={self.disabled}")
        if not self.disabled and (pl_module.global_step > 0 or self.log_first_step):
            print(f"[ImageLogger.on_train_batch_end] Calling log_img...")
            self.log_img(pl_module, batch, batch_idx, split="train")

    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):
        # â­ ç¦ç”¨éªŒè¯é˜¶æ®µçš„å›¾ç‰‡è®°å½•ï¼Œé¿å… DDIM é‡‡æ ·å¯¼è‡´éªŒè¯è¿‡ç¨‹è¿‡æ…¢
        # éªŒè¯é˜¶æ®µçš„ log_images ä¼šè§¦å‘ 50+ æ­¥ DDIM æ¨ç†ï¼Œéå¸¸è€—æ—¶
        pass
        if hasattr(pl_module, 'calibrate_grad_norm'):
            if (pl_module.calibrate_grad_norm and batch_idx % 25 == 0) and batch_idx > 0:
                self.log_gradients(trainer, pl_module, batch_idx=batch_idx)


class CUDACallback(Callback):
    # see https://github.com/SeanNaren/minGPT/blob/master/mingpt/callback.py
    def on_train_epoch_start(self, trainer, pl_module):
        # Reset the memory use counter
        torch.cuda.reset_peak_memory_stats(trainer.root_gpu)
        torch.cuda.synchronize(trainer.root_gpu)
        self.start_time = time.time()
        print(f"\n[CUDACallback] ğŸš€ Starting Epoch {pl_module.current_epoch}...")

    def on_train_epoch_end(self, trainer, pl_module, outputs):
        torch.cuda.synchronize(trainer.root_gpu)
        max_memory = torch.cuda.max_memory_allocated(trainer.root_gpu) / 2 ** 20
        epoch_time = time.time() - self.start_time

        try:
            max_memory = trainer.training_type_plugin.reduce(max_memory)
            epoch_time = trainer.training_type_plugin.reduce(epoch_time)

            rank_zero_info(f"Average Epoch time: {epoch_time:.2f} seconds")
            rank_zero_info(f"Average Peak memory {max_memory:.2f}MiB")
        except AttributeError:
            pass


if __name__ == "__main__":

    now = datetime.datetime.now().strftime("%Y-%m-%dT%H-%M-%S")
    sys.path.append(os.getcwd())

    parser = get_parser()
    parser = Trainer.add_argparse_args(parser)

    opt, unknown = parser.parse_known_args()
    
    if opt.debug:
        os.environ["CUDA_VISIBLE_DEVICES"] = "1"
    
    if opt.name and opt.resume:
        raise ValueError(
            "-n/--name and -r/--resume cannot be specified both."
            "If you want to resume training in a new log folder, "
            "use -n/--name in combination with --resume_from_checkpoint"
        )
    if opt.resume:
        if not os.path.exists(opt.resume):
            raise ValueError("Cannot find {}".format(opt.resume))
        if os.path.isfile(opt.resume):
            paths = opt.resume.split("/")
            logdir = "/".join(paths[:-2])
            ckpt = opt.resume
        else:
            assert os.path.isdir(opt.resume), opt.resume
            logdir = opt.resume.rstrip("/")
            ckpt = os.path.join(logdir, "checkpoints", "last.ckpt")

        opt.resume_from_checkpoint = ckpt
        base_configs = sorted(glob.glob(os.path.join(logdir, "configs/*.yaml")))
        opt.base = base_configs + opt.base
        _tmp = logdir.split("/")
        nowname = _tmp[-1]
    else:
        if opt.name:
            name = "_" + opt.name
        elif opt.base:
            cfg_fname = os.path.split(opt.base[0])[-1]
            cfg_name = os.path.splitext(cfg_fname)[0]
            name = "_" + cfg_name
        else:
            name = ""
        nowname = now + name + opt.postfix
        logdir = os.path.join(opt.logdir, nowname)

    ckptdir = os.path.join(logdir, "checkpoints")
    cfgdir = os.path.join(logdir, "configs")
    seed_everything(opt.seed)

    # init and save configs
    configs = [OmegaConf.load(cfg) for cfg in opt.base]
    cli = OmegaConf.from_dotlist(unknown)
    config = OmegaConf.merge(*configs, cli)
    lightning_config = config.pop("lightning", OmegaConf.create())
    # merge trainer cli with config
    trainer_config = lightning_config.get("trainer", OmegaConf.create())
    for k in nondefault_trainer_args(opt):
        trainer_config[k] = getattr(opt, k)

    # ä¸ main.py ä¿æŒä¸€è‡´ï¼šåªè¦æä¾›äº† gpus/devices å°±å¯ç”¨ GPUï¼›å¦åˆ™é€€å› CPU
    if "gpus" in trainer_config or "devices" in trainer_config:
        # PyTorch Lightning 1.4.2 ä½¿ç”¨ gpus è€Œä¸æ˜¯ devices
        # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å‚æ•°åç§°
        num_gpus = None
        if "gpus" in trainer_config:
            g = trainer_config["gpus"]
            if isinstance(g, str):
                gpu_ids = [x for x in g.replace(" ", "").split(",") if x != ""]
                num_gpus = len(gpu_ids) if gpu_ids else 1
            elif isinstance(g, int):
                num_gpus = g if g > 0 else 1
            else:
                num_gpus = 1
        elif "devices" in trainer_config:
            # å¦‚æœé…ç½®ä¸­ä½¿ç”¨äº† devicesï¼Œå°†å…¶è½¬æ¢ä¸º gpusï¼ˆPL 1.4.2å…¼å®¹ï¼‰
            num_gpus = trainer_config["devices"]
            trainer_config["gpus"] = num_gpus
            # åˆ é™¤ devices å‚æ•°ï¼Œå› ä¸º PL 1.4.2 ä¸æ”¯æŒ
            del trainer_config["devices"]
        
        # PL 1.4.2 ä¸éœ€è¦æ˜¾å¼è®¾ç½® accelerator='gpu'ï¼Œæœ‰ gpus å‚æ•°å°±å¤Ÿäº†
        # å¦‚æœæ˜¾å¼è®¾ç½® acceleratorï¼Œå¯èƒ½ä¼šå¯¼è‡´å†²çª
        if "accelerator" in trainer_config:
            del trainer_config["accelerator"]
        
        # å¤šå¡æ—¶é»˜è®¤ ddpï¼›å•å¡åˆ™ä¸å¼ºåˆ¶ distributed_backend
        # pytorch-lightning 1.4.2 ä½¿ç”¨ distributed_backend è€Œä¸æ˜¯ strategy
        if num_gpus and num_gpus > 1:
            trainer_config.setdefault("distributed_backend", "ddp")
        cpu = False
        print(f"Using GPU training with gpus={trainer_config.get('gpus', num_gpus)}")
    else:
        trainer_config.pop("accelerator", None)
        trainer_config.pop("devices", None)
        cpu = True
        print("Running on CPU")

    # ä» trainer_config ä¸­æå– distributed_backendï¼Œé¿å…ä¼ é€’ç»™ Trainer.from_argparse_args
    # pytorch-lightning 1.4.2 ä¸­ distributed_backend åº”è¯¥é€šè¿‡ kwargs ä¼ é€’ï¼Œè€Œä¸æ˜¯ argparse
    distributed_backend_value = trainer_config.pop("distributed_backend", None)
    
    trainer_opt = argparse.Namespace(**trainer_config)
    lightning_config.trainer = trainer_config
    
    # å¤„ç†wandb resumeé€»è¾‘
    if opt.resume:
        # å¦‚æœæ˜¯resumeè®­ç»ƒï¼Œä½¿ç”¨"allow"æ¨¡å¼ï¼Œwandbä¼šå°è¯•æ¢å¤æˆ–åˆ›å»ºæ–°run
        wandb_resume = "allow"
        wandb_id = nowname  # ä½¿ç”¨ç›¸åŒçš„IDæ¥æ¢å¤run
    else:
        # æ–°è®­ç»ƒï¼Œä¸resume
        wandb_resume = None
        wandb_id = nowname
    
    # ä»é…ç½®æ–‡ä»¶è¯»å– wandb é…ç½®
    wandb_config = lightning_config.get("wandb", OmegaConf.create())
    wandb_project = wandb_config.get("project", "Face_Swapping_Debug" if opt.debug else "Face_Swapping")
    wandb_run_name = wandb_config.get("run_name", nowname) or nowname  # å¦‚æœä¸ºNoneåˆ™ä½¿ç”¨nowname
    wandb_tags = wandb_config.get("tags", [])
    wandb_notes = wandb_config.get("notes", "")
    
    print(f"[WANDB Config] Project: {wandb_project}, Run Name: {wandb_run_name}")
    if wandb_tags:
        print(f"[WANDB Config] Tags: {wandb_tags}")
    
    # æ‰‹åŠ¨åˆå§‹åŒ– wandbï¼ˆåŸå§‹æ–¹å¼ï¼‰- åªåœ¨ä¸»è¿›ç¨‹
    import torch.distributed as dist
    
    # æ£€æŸ¥å½“å‰è¿›ç¨‹çš„ rank
    if dist.is_initialized():
        rank = dist.get_rank()
    else:
        rank = 0
    
    if rank == 0:
        # â­ æ–¹æ¡ˆé€‰æ‹©è¯´æ˜ï¼š
        # - WANDB_MODE="disabled": å®Œå…¨ç¦ç”¨wandbï¼ˆæ¨èï¼Œé¿å…é˜»å¡ï¼‰
        # - WANDB_MODE="offline": ç¦»çº¿æ¨¡å¼ï¼Œæ•°æ®ä¿å­˜æœ¬åœ°ï¼ˆå¯åç»­æ‰‹åŠ¨åŒæ­¥ï¼‰
        # - WANDB_MODE="online": åœ¨çº¿æ¨¡å¼ï¼ˆå·²ä¼˜åŒ–éé˜»å¡ï¼Œä½†ä»å¯èƒ½æœ‰ç½‘ç»œå»¶è¿Ÿï¼‰
        
        wandb_mode = os.environ.get("WANDB_MODE", "online")
        print(f"[WANDB Rank {rank}] Mode: {wandb_mode}")
        
        # â­ é…ç½® wandb settings - éé˜»å¡æ¨¡å¼
        wandb_settings = wandb.Settings(
            mode=wandb_mode,       # ä½¿ç”¨ç¯å¢ƒå˜é‡æ§åˆ¶æ¨¡å¼
            start_method="fork",   # å¤šè¿›ç¨‹å…¼å®¹
            _disable_stats=False,  # å¯ç”¨ç³»ç»Ÿç»Ÿè®¡
            _disable_meta=False,   # å¯ç”¨å…ƒæ•°æ®
            _save_requirements=False,  # ä¸ä¿å­˜ requirements
            _file_stream_timeout_seconds=30,  # æ–‡ä»¶æµè¶…æ—¶
            _stats_sample_rate_seconds=30,  # é™ä½ç»Ÿè®¡é‡‡æ ·é¢‘ç‡
            _stats_samples_to_average=10,  # ç»Ÿè®¡æ ·æœ¬å¹³å‡æ•°
        )
        
        print(f"[WANDB Rank {rank}] Initializing with mode={wandb_mode}")
    else:
        print(f"[WANDB Rank {rank}] Skipping wandb init (not main process)")
        # â­ é‡è¦ï¼šéä¸»è¿›ç¨‹å®Œå…¨ä¸ä½¿ç”¨wandbï¼Œé¿å…DDPæ­»é”
        os.environ["WANDB_MODE"] = "disabled"
        wandb_mode = "disabled"
    
    # â­ åªæœ‰rank 0æ‰åˆå§‹åŒ–wandb
    if rank == 0:
        # ç¡®ä¿ wandb ç›®å½•æœ‰å†™æƒé™
        wandb_dir = os.path.join(logdir, "wandb")
        os.makedirs(wandb_dir, exist_ok=True)
        
        # æµ‹è¯•å†™æƒé™
        try:
            test_file = os.path.join(wandb_dir, ".test_write")
            with open(test_file, 'w') as f:
                f.write("test")
            os.remove(test_file)
            print(f"[WANDB Rank {rank}] Using wandb dir: {wandb_dir}")
        except Exception as e:
            print(f"[WANDB Rank {rank}] WARNING: {wandb_dir} not writable ({e}), using /tmp")
            wandb_dir = "/tmp/wandb_logs"
            os.makedirs(wandb_dir, exist_ok=True)
        
        # ç»Ÿä¸€åˆå§‹åŒ– wandbï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°
        wandb.init(
            project=wandb_project, 
            name=wandb_run_name, 
            tags=list(wandb_tags) if wandb_tags else None,
            notes=wandb_notes if wandb_notes else None,
            config=vars(opt), 
            dir=wandb_dir, 
            resume=wandb_resume, 
            id=wandb_id,
            settings=wandb_settings,
            reinit=False
        )
        
        # éªŒè¯ wandb åˆå§‹åŒ–
        print(f"[WANDB Rank {rank}] wandb.run is {'INITIALIZED' if wandb.run is not None else 'None (ERROR!)'}")
        if wandb.run is not None:
            print(f"[WANDB] Run name: {wandb.run.name}, ID: {wandb.run.id}")
            print(f"[WANDB] URL: {wandb.run.url}")
            print(f"[WANDB] Mode: {wandb.run.mode}")
            print(f"[WANDB] Current step: {wandb.run.step}")
    else:
        print(f"[WANDB Rank {rank}] Skipping wandb.init() - not main process")
    
    print(config)

    # model
    model = instantiate_from_config(config.model)
    
    # ------------------- ä¿®æ”¹åçš„åŠ è½½é€»è¾‘å¼€å§‹ -------------------
    if not opt.resume:
        # è¿™æ˜¯"å¼€å§‹æ–°DPOè®­ç»ƒ"çš„é€»è¾‘
        print(f"Loading base model for NEW training from: {opt.pretrained_model}")
        if not os.path.exists(opt.pretrained_model):
            raise FileNotFoundError(f"Cannot find pretrained model at {opt.pretrained_model}")

        # 1. åŠ è½½åŸºç¡€æ¨¡å‹ (e.g., sd-v1-4.ckpt) çš„ state dict
        base_sd = torch.load(opt.pretrained_model, map_location='cpu')['state_dict']
        
        # 2. åˆ›å»ºä¸€ä¸ªæ–°çš„ state_dict
        dpo_state_dict = {}
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ SFT æ¨¡å¼
        use_sft_mode = config.model.params.get('use_sft_loss', False)
        
        if use_sft_mode:
            print("âœ“ SFT æ¨¡å¼ï¼šåªåŠ è½½ç­–ç•¥æ¨¡å‹æƒé‡ï¼ˆè·³è¿‡å‚è€ƒæ¨¡å‹ï¼ŒèŠ‚çœæ˜¾å­˜ï¼‰")
        else:
            print("DPO æ¨¡å¼ï¼šåŠ è½½ç­–ç•¥æ¨¡å‹å’Œå‚è€ƒæ¨¡å‹æƒé‡...")
        
        total_copied_to_ref = 0
        
        # 3. éå†åŸºç¡€æ¨¡å‹çš„æ‰€æœ‰æƒé‡
        for key, value in base_sd.items():
            
            # 3a. å°†æƒé‡æŒ‰åŸæ ·å¤åˆ¶. è¿™ä¼šå¡«å……:
            # - self.first_stage_model.*
            # - self.cond_stage_model.*
            # - self.model.* (å³ ç­–ç•¥æ¨¡å‹/Policy Model)
            dpo_state_dict[key] = value

            # 3b. â­ åªåœ¨ DPO æ¨¡å¼ä¸‹å¤åˆ¶å‚è€ƒæ¨¡å‹æƒé‡
            if not use_sft_mode:
                # æ£€æŸ¥è¿™ä¸ªé”®æ˜¯å¦å±äº UNet (æ ¹æ®ä½ çš„é”™è¯¯æ—¥å¿—, UNet é”®ä»¥ "model.diffusion_model" å¼€å¤´)
                unet_prefix = "model.diffusion_model"
                if key.startswith(unet_prefix):
                    
                    # 3c. ä¸ºå‚è€ƒæ¨¡å‹(Reference Model)åˆ›å»ºå¯¹åº”çš„é”®
                    # ä¾‹å¦‚: "model.diffusion_model.X" -> "model_ref.diffusion_model.X"
                    # (æ³¨æ„: "model." è¢«æ›¿æ¢ä¸º "model_ref.")
                    ref_key = "model_ref." + key[len("model."):] 
                    
                    # 3d. ä¸ºå‚è€ƒæ¨¡å‹æ·»åŠ æƒé‡çš„ *å‰¯æœ¬*
                    dpo_state_dict[ref_key] = value.clone()
                    total_copied_to_ref += 1

        print(f"Total keys in base model: {len(base_sd)}")
        if not use_sft_mode:
            print(f"Total keys copied to ref_model (UNet only): {total_copied_to_ref}")
        else:
            print(f"SFT æ¨¡å¼ï¼šè·³è¿‡å‚è€ƒæ¨¡å‹æƒé‡å¤åˆ¶")

        # 4. å°†è¿™ä¸ªåˆå¹¶åçš„ state_dict åŠ è½½åˆ°ä½ çš„ LatentDiffusion æ¨¡å‹ä¸­
        #    ä½¿ç”¨ strict=False æ˜¯å¸¸è§„æ“ä½œï¼Œå› ä¸ºåŸºç¡€æ¨¡å‹ state_dict åŒ…å« VAE å’Œ CLIPï¼Œ
        #    è€Œä½ çš„ LatentDiffusion ç±»æœ¬èº«æ²¡æœ‰ç›´æ¥å®šä¹‰å®ƒä»¬ (å®ƒä»¬åœ¨ first_stage_model ç­‰å­æ¨¡å—ä¸­)
        missing_keys, unexpected_keys = model.load_state_dict(dpo_state_dict, strict=False)
        
        print(f"Successfully loaded weights.")
        print(f"  Missing Keys: {len(missing_keys)}")
        print(f"  Unexpected Keys: {len(unexpected_keys)}")
        
        # â­ åªåœ¨ DPO æ¨¡å¼ä¸‹æ£€æŸ¥å‚è€ƒæ¨¡å‹
        if not use_sft_mode and total_copied_to_ref == 0:
            print("\n\n*** ä¸¥é‡è­¦å‘Š ***")
            print("åœ¨æ‚¨çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½• 'model.diffusion_model' å¼€å¤´çš„é”®ã€‚")
            print("è¿™æ„å‘³ç€æ‚¨çš„ 'model_ref' (å‚è€ƒæ¨¡å‹) æ²¡æœ‰è¢«æ­£ç¡®åˆå§‹åŒ–ï¼ŒDPO è®­ç»ƒå°†å¤±è´¥ã€‚")
            print("è¯·æ£€æŸ¥æ‚¨çš„ --pretrained_model æ–‡ä»¶æ˜¯å¦æ­£ç¡®ã€‚")
            print("************************\n\n")

    else:
        # è¿™æ˜¯"æ¢å¤è®­ç»ƒ"çš„é€»è¾‘
        # (å½“ä½ ä½¿ç”¨ -r æ—¶ï¼Œtrainer.fit() ä¼šè‡ªåŠ¨åŠ è½½æ£€æŸ¥ç‚¹, æ— éœ€é¢å¤–ä»£ç )
        print(f"Resuming training from checkpoint: {opt.resume_from_checkpoint}")
    
    # ------------------- ä¿®æ”¹åçš„åŠ è½½é€»è¾‘ç»“æŸ -------------------

    trainer_kwargs = dict()

    # default logger configs
    # ä½¿ç”¨ testtube ä½œä¸º PyTorch Lightning loggerï¼Œwandb é€šè¿‡æ‰‹åŠ¨ init ç®¡ç†
    default_logger_cfgs = {
        "wandb": {
            "target": "pytorch_lightning.loggers.WandbLogger",
            "params": {
                "project": "Face_Swapping_Debug" if opt.debug else "Face_Swapping",
                "name": nowname,
                "save_dir": logdir,
                "offline": opt.debug,
                "id": wandb_id,
                "resume": wandb_resume,
            }
        },
        "testtube": {
            "target": "pytorch_lightning.loggers.TestTubeLogger",
            "params": {
                "name": "testtube",
                "save_dir": logdir,
            }
        },
    }
    # ä½¿ç”¨ testtube loggerï¼Œwandb å•ç‹¬ç®¡ç†
    default_logger_cfg = default_logger_cfgs["testtube"]
    if "logger" in lightning_config:
        logger_cfg = lightning_config.logger
    else:
        logger_cfg = OmegaConf.create()
    logger_cfg = OmegaConf.merge(default_logger_cfg, logger_cfg)
    trainer_kwargs["logger"] = instantiate_from_config(logger_cfg)

    # modelcheckpoint - use TrainResult/EvalResult(checkpoint_on=metric) to
    # specify which metric is used to determine best models
    default_modelckpt_cfg = {
        "target": "pytorch_lightning.callbacks.ModelCheckpoint",
        "params": {
            "dirpath": ckptdir,
            "filename": "{epoch:06}",
            "verbose": True,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
            "save_last": True,
        }
    }
    if hasattr(model, "monitor"):
        print(f"Monitoring {model.monitor} as checkpoint metric.")
        default_modelckpt_cfg["params"]["monitor"] = model.monitor
        default_modelckpt_cfg["params"]["save_top_k"] = 30

    if "modelcheckpoint" in lightning_config:
        modelckpt_cfg = lightning_config.modelcheckpoint
    else:
        modelckpt_cfg =  OmegaConf.create()
    modelckpt_cfg = OmegaConf.merge(default_modelckpt_cfg, modelckpt_cfg)
    print(f"Merged modelckpt-cfg: \n{modelckpt_cfg}")
    if version.parse(pl.__version__) < version.parse('1.4.0'):
        trainer_kwargs["checkpoint_callback"] = instantiate_from_config(modelckpt_cfg)

    # add callback which sets up log directory
    default_callbacks_cfg = {
        "setup_callback": {
            "target": "main_dpo.SetupCallback",
            "params": {
                "resume": opt.resume,
                "now": now,
                "logdir": logdir,
                "ckptdir": ckptdir,
                "cfgdir": cfgdir,
                "config": config,
                "lightning_config": lightning_config,
            }
        },
        "image_logger": {
            "target": "main_dpo.ImageLogger",
            "params": {
                "batch_frequency":50,
                "max_images": 3,
                "clamp": True,
                "log_first_step": False  # é¿å…ç¬¬ä¸€æ­¥å°±è®°å½•å›¾åƒï¼Œæå‡å¯åŠ¨é€Ÿåº¦
            }
        },
        "learning_rate_logger": {
            "target": "pytorch_lightning.callbacks.LearningRateMonitor",
            "params": {
                "logging_interval": "step",
            }
        },
        "cuda_callback": {
            "target": "main_dpo.CUDACallback"
        },
    }
    if version.parse(pl.__version__) >= version.parse('1.4.0'):
        default_callbacks_cfg.update({'checkpoint_callback': modelckpt_cfg})

    if "callbacks" in lightning_config:
        callbacks_cfg = lightning_config.callbacks
    else:
        callbacks_cfg = OmegaConf.create()

    if 'metrics_over_trainsteps_checkpoint' in callbacks_cfg:
        print(
            'Caution: Saving checkpoints every n train steps without deleting. This might require some free space.')
        default_metrics_over_trainsteps_ckpt_dict = {
            'metrics_over_trainsteps_checkpoint':
                {"target": 'pytorch_lightning.callbacks.ModelCheckpoint',
                    'params': {
                        "dirpath": os.path.join(ckptdir, 'trainstep_checkpoints'),
                        "filename": "{epoch:06}-{step:09}",
                        "verbose": True,
                        'save_top_k': -1,
                        'every_n_train_steps': 10000,
                        'save_weights_only': True
                    }
                    }
        }
        default_callbacks_cfg.update(default_metrics_over_trainsteps_ckpt_dict)

    callbacks_cfg = OmegaConf.merge(default_callbacks_cfg, callbacks_cfg)
    if 'ignore_keys_callback' in callbacks_cfg and hasattr(trainer_opt, 'resume_from_checkpoint'):
        callbacks_cfg.ignore_keys_callback.params['ckpt_path'] = trainer_opt.resume_from_checkpoint
    elif 'ignore_keys_callback' in callbacks_cfg:
        del callbacks_cfg['ignore_keys_callback']

    trainer_kwargs["callbacks"] = [instantiate_from_config(callbacks_cfg[k]) for k in callbacks_cfg]

    # PyTorch Lightning 1.4.2 ä½¿ç”¨ gpus è€Œä¸æ˜¯ devicesï¼Œä¸éœ€è¦æ˜¾å¼ä¼ é€’ accelerator
    # gpus å‚æ•°å·²ç»åœ¨ trainer_config ä¸­ï¼Œä¼šé€šè¿‡ trainer_opt ä¼ é€’
    # ç¡®ä¿ä¸ä¼ é€’ PL 1.4.2 ä¸æ”¯æŒçš„å‚æ•°
    if "devices" in trainer_kwargs:
        del trainer_kwargs["devices"]
    if "accelerator" in trainer_kwargs:
        del trainer_kwargs["accelerator"]
    
    # pytorch-lightning 1.4.2 ä½¿ç”¨ distributed_backend è€Œä¸æ˜¯ strategy
    # é€šè¿‡ kwargs ä¼ é€’ distributed_backendï¼Œè€Œä¸æ˜¯é€šè¿‡ argparse
    if distributed_backend_value is not None:
        trainer_kwargs["distributed_backend"] = distributed_backend_value

    trainer = Trainer.from_argparse_args(trainer_opt, **trainer_kwargs)
    trainer.logdir = logdir

    # data
    data = instantiate_from_config(config.data)
    # NOTE according to https://pytorch-lightning.readthedocs.io/en/latest/datamodules.html
    # calling these ourselves should not be necessary but it is.
    # lightning still takes care of proper multiprocessing though
    data.prepare_data()
    data.setup()
    print("#### Data #####")
    for k in data.datasets:
        print(f"{k}, {data.datasets[k].__class__.__name__}, {len(data.datasets[k])}")

    # configure learning rate
    bs, base_lr = config.data.params.batch_size, config.model.base_learning_rate
    if not cpu:
        # å¤„ç† gpus å‚æ•°å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•´æ•°çš„æƒ…å†µ
        gpus_param = lightning_config.trainer.gpus
        if isinstance(gpus_param, str):
            ngpu = len(gpus_param.strip(",").split(','))
        elif isinstance(gpus_param, int):
            ngpu = gpus_param if gpus_param > 0 else 1
        else:
            ngpu = 1
    else:
        ngpu = 1
    if 'accumulate_grad_batches' in lightning_config.trainer:
        accumulate_grad_batches = lightning_config.trainer.accumulate_grad_batches
    else:
        accumulate_grad_batches = 1
    num_nodes = 1
    print(f"accumulate_grad_batches = {accumulate_grad_batches}")
    lightning_config.trainer.accumulate_grad_batches = accumulate_grad_batches
    if opt.scale_lr:
        model.learning_rate = accumulate_grad_batches * num_nodes * ngpu * bs * base_lr
        print(
            "Setting learning rate to {:.2e} = {} (accumulate_grad_batches) * {} (num_nodes) * {} (num_gpus) * {} (batchsize) * {:.2e} (base_lr)".format(
                model.learning_rate, accumulate_grad_batches, num_nodes, ngpu, bs, base_lr))
    else:
        model.learning_rate = base_lr
        print("++++ NOT USING LR SCALING ++++")
        print(f"Setting learning rate to {model.learning_rate:.2e}")


    # allow checkpointing via USR1
    def melk(*args, **kwargs):
        # run all checkpoint hooks
        if trainer.global_rank == 0:
            print("Summoning checkpoint.")
            ckpt_path = os.path.join(ckptdir, "last.ckpt")
            trainer.save_checkpoint(ckpt_path)


    def divein(*args, **kwargs):
        if trainer.global_rank == 0:
            import pudb;
            pudb.set_trace()


    import signal
    import atexit
    import threading

    # åˆ›å»ºä¸€ä¸ªæ ‡å¿—æ¥è·Ÿè¸ªæ˜¯å¦å·²ç»ä¿å­˜è¿‡checkpointï¼ˆé¿å…é‡å¤ä¿å­˜ï¼‰
    _checkpoint_saved = threading.Lock()
    _saving_checkpoint = False

    def safe_save_checkpoint():
        """å®‰å…¨åœ°ä¿å­˜checkpointï¼Œé¿å…é‡å¤ä¿å­˜"""
        global _saving_checkpoint
        with _checkpoint_saved:
            if _saving_checkpoint:
                return  # å·²ç»åœ¨ä¿å­˜ä¸­ï¼Œè·³è¿‡
            _saving_checkpoint = True
        
        try:
            # æ£€æŸ¥traineræ˜¯å¦å·²åˆå§‹åŒ–ä¸”æ˜¯ä¸»è¿›ç¨‹
            if trainer is not None:
                # åœ¨å¤šè¿›ç¨‹ç¯å¢ƒä¸‹ï¼Œåªæœ‰rank 0ä¿å­˜
                if hasattr(trainer, 'global_rank'):
                    if trainer.global_rank == 0:
                        print("\n[Checkpoint] Saving checkpoint...")
                        melk()
                        print("[Checkpoint] Checkpoint saved successfully.")
                else:
                    # å•è¿›ç¨‹ç¯å¢ƒ
                    print("\n[Checkpoint] Saving checkpoint...")
                    melk()
                    print("[Checkpoint] Checkpoint saved successfully.")
        except Exception as e:
            print(f"[Checkpoint] Error saving checkpoint: {e}")
            import traceback
            traceback.print_exc()
        finally:
            with _checkpoint_saved:
                _saving_checkpoint = False

    # æ³¨å†Œé€€å‡ºæ—¶çš„æ¸…ç†å‡½æ•°ï¼Œç¡®ä¿è¿›ç¨‹é€€å‡ºæ—¶ä¿å­˜checkpoint
    def save_checkpoint_on_exit():
        """è¿›ç¨‹é€€å‡ºæ—¶ä¿å­˜checkpoint"""
        safe_save_checkpoint()
    
    # æ³¨å†Œatexitå¤„ç†å‡½æ•°ï¼ˆæ³¨æ„ï¼šSIGKILLæ— æ³•è¢«æ•è·ï¼Œä½†SIGTERMå¯ä»¥ï¼‰
    atexit.register(save_checkpoint_on_exit)

    # å¤„ç†SIGTERMä¿¡å·ï¼ˆkillå‘½ä»¤é»˜è®¤å‘é€çš„ä¿¡å·ï¼‰
    def sigterm_handler(signum, frame):
        """å¤„ç†SIGTERMä¿¡å·ï¼ˆkillå‘½ä»¤ï¼‰"""
        print(f"\n[SIGTERM] Received termination signal (kill)")
        safe_save_checkpoint()
        print("[SIGTERM] Exiting...")
        # ä½¿ç”¨os._exitå¼ºåˆ¶é€€å‡ºï¼Œé¿å…è¢«å…¶ä»–ä¿¡å·å¤„ç†å¹²æ‰°
        os._exit(0)
    
    # å¤„ç†SIGINTä¿¡å·ï¼ˆCtrl+Cï¼‰ï¼Œç¡®ä¿èƒ½å¤Ÿä¸­æ–­
    def sigint_handler(signum, frame):
        """å¤„ç†SIGINTä¿¡å·ï¼ˆCtrl+Cï¼‰"""
        print(f"\n[SIGINT] Received interrupt signal (Ctrl+C)")
        safe_save_checkpoint()
        print("[SIGINT] Exiting...")
        # ä½¿ç”¨os._exitå¼ºåˆ¶é€€å‡º
        os._exit(0)

    signal.signal(signal.SIGUSR1, melk)
    signal.signal(signal.SIGUSR2, divein)
    signal.signal(signal.SIGTERM, sigterm_handler)  # å¤„ç†killå‘½ä»¤
    signal.signal(signal.SIGINT, sigint_handler)    # å¤„ç†Ctrl+C

    # run
    if opt.train:
        try:
            print(f"[TRAINING] Starting training with {trainer.max_epochs} epochs...")
            print(f"[TRAINING] Current callbacks: {[type(cb).__name__ for cb in trainer.callbacks]}")
            # pytorch-lightning 1.4.2 ä½¿ç”¨ distributed_backend è€Œä¸æ˜¯ strategy
            ddp_info = getattr(trainer, 'distributed_backend', None) or getattr(trainer, 'strategy', 'N/A')
            print(f"[TRAINING] DDP enabled: {ddp_info}")
            
            trainer.fit(model, data)
            
            print(f"[TRAINING] Training completed successfully!")
        except KeyboardInterrupt:
            # â­ ä¸“é—¨å¤„ç† Ctrl+Cï¼ˆå¤‡ç”¨ï¼Œå¦‚æœä¿¡å·å¤„ç†å¤±è´¥ï¼‰
            print("\n[KeyboardInterrupt] Training interrupted by user (Ctrl+C)")
            try:
                if trainer.global_rank == 0:
                    melk()  # ä¿å­˜checkpoint
                print("Checkpoint saved. Exiting...")
            except Exception as e:
                print(f"Error saving checkpoint: {e}")
            sys.exit(0)
        except Exception:
            # å…¶ä»–å¼‚å¸¸ä¹Ÿä¿å­˜
            try:
                if trainer.global_rank == 0:
                    melk()
            except:
                pass
            raise
    if not opt.no_test and not trainer.interrupted:
        trainer.test(model, data)
